{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, MetaData, Table, Column, Integer, String, DateTime, Float, select, Date, JSON\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from math import ceil\n",
    "from tqdm import tqdm\n",
    "\n",
    "from wikibaseintegrator import wbi_core, wbi_login, wbi_login\n",
    "from wikibaseintegrator.wbi_config import config as wbi_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_items_by_label(label_list:list, item_type:str, is_unique:bool = True, is_notnull:bool = True):\n",
    "    '''\n",
    "    По переданному списку лейблов находит entity_id в базе Wikibase. \n",
    "    \n",
    "    label_list: список искомых лейблов\n",
    "    item_type: тип искомого объекта. Если не указано, то любой объект. Если указано:\n",
    "        \"P\" - Property\n",
    "        \"Q\" - Item\n",
    "    is_unique: если True, то вернёт ошибку, если найдено больше одного значения\n",
    "    is_notnull: если True, то вернёт ошибку, если не найдено ни одного значения\n",
    "    '''\n",
    "    \n",
    "    query = \"\"\"\n",
    "        SELECT DISTINCT ?item ?itemLabel\n",
    "        WHERE {{\n",
    "          ?item rdfs:label ?itemLabel. \n",
    "\n",
    "          VALUES ?itemLabel {{ {label_filter} }}\n",
    "        }}\"\"\".format(label_filter = ' '.join([f'\\\"{i}\\\"@en' for i in label_list]))\n",
    "    \n",
    "    result = wbi_core.ItemEngine.execute_sparql_query(query)\n",
    "    result_list = [[i['itemLabel']['value'], i['item']['value'].replace('http://wikibase.svc/entity/', '')] \n",
    "                   for i in result['results']['bindings']]\n",
    "    \n",
    "    df = pd.DataFrame(result_list, columns = ['label', 'item'])\n",
    "        \n",
    "    if item_type in ('P', 'Q'):\n",
    "        df = df[df.item.str.contains(item_type)] \n",
    "\n",
    "    df_check = df.groupby('label').count()\n",
    "    if is_unique and df_check.item.max() > 1:\n",
    "        r = df[df.label.isin(df_check[df_check.item > 1].index.to_list())].sort_values(by = 'label')\n",
    "        raise Exception(f\"entity_id определён неоднозначно: \\n{r}\")\n",
    "    elif is_notnull and len(set(label_list) - set(df.label)) > 0:\n",
    "        r = set(label_list) - set(df.label)\n",
    "        raise Exception(f\"entity_id не найден: \\n{r}!\")\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BRICKIT_BD_LOGIN = 'postgres'\n",
    "BRICKIT_BD_PASSWORD = 'pass'\n",
    "BRICKIT_BD_HOST = 'host'\n",
    "WIKIBASE_HOST = 'wiki_host'\n",
    "\n",
    "WIKIBASE_LOGIN = 'WikibaseAdmin'\n",
    "WIKIBASE_PASSWORD = 'WikibaseDockerAdminPass'\n",
    "\n",
    "connection_string = f'postgresql://{BRICKIT_BD_LOGIN}:{BRICKIT_BD_PASSWORD}@{BRICKIT_BD_HOST}:5432/holybricks'\n",
    "engine_pg = create_engine(connection_string)\n",
    "\n",
    "wbi_config['MEDIAWIKI_API_URL'] = f'http://{WIKIBASE_HOST}:8181/api.php'\n",
    "wbi_config['SPARQL_ENDPOINT_URL'] = f'http://{WIKIBASE_HOST}:8989/bigdata/sparql'\n",
    "wbi_config['WIKIBASE_URL'] = 'http://wikibase.svc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Легаси, уже умеем нормально\n",
    "ITEMS_DICT = {\n",
    "    'I': {\n",
    "        'Brickit Company': 'Q1',\n",
    "        'Brickit Image': 'Q2',\n",
    "        'Brickit Part': 'Q3'\n",
    "\n",
    "    },\n",
    "    'P': {\n",
    "        'instance of': 'P1',\n",
    "        'Image URL': 'P2',\n",
    "        'Image ID': 'P3',\n",
    "        'Part Name': 'P4',\n",
    "        'Part Tag': 'P5',\n",
    "        'Part Image': 'P6',\n",
    "        'Part Num': 'P7',\n",
    "        'Part Child': 'P8'\n",
    "    }    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Забрать какие-то данные из Brickit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_images = pd.read_sql(f\"\"\"\n",
    "SELECT id, public_url\n",
    "FROM staging.manual_images\n",
    "WHERE initial_entity_type = 'part'\n",
    "    \"\"\", con = engine_pg)\n",
    "\n",
    "\n",
    "df_parts = pd.read_sql(f\"\"\"\n",
    "SELECT part_num, \"name\", tag, part_cat_id, child_part_nums, image_id\n",
    "FROM staging.synthetic_parts\n",
    "    \"\"\", con = engine_pg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Залить сущности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Костыль для связки наша сущность - ID в Wikibase/\n",
    "# Предполагаем, что это можно взять при помощи SPARQL\n",
    "# А пока что по результатам циклов ниже в эти датафреймы дописывается ID Wikibase и сохраняются в csv\n",
    "# df_images = pd.read_csv('./df_images.csv')\n",
    "# df_parts = pd.read_csv('./df_parts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "login_instance = wbi_login.Login(user=WIKIBASE_LOGIN, pwd=WIKIBASE_PASSWORD)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузить 100 изображений из всех\n",
    "for _, img_i in df_images[:100].iterrows():\n",
    "    data = [\n",
    "        wbi_core.Url(str(img_i['public_url']), prop_nr=ITEMS_DICT['P']['Image URL']),\n",
    "        wbi_core.String(str(img_i['id']), prop_nr=ITEMS_DICT['P']['Image ID']),\n",
    "        wbi_core.ItemID(ITEMS_DICT['I']['Brickit Image'], prop_nr=ITEMS_DICT['P']['instance of'])\n",
    "    ]\n",
    "    item = wbi_core.ItemEngine(new_item=True, data=data,core_props=set())\n",
    "    \n",
    "    # Этот метод в библиотеке из коробки не работает. \n",
    "    # Надо либо закомментить в библиотеке в wbi_core.ItemEngine.set_label() условие после \"Skip set_label if the item already have one and if_exists is at 'KEEP'\"\n",
    "    # Либо просто не проставлять лейблы\n",
    "    item.set_label('img_' + str(img_i['id']), if_exists='REPLACE')\n",
    "    \n",
    "    r = item.write(login_instance)    \n",
    "    \n",
    "    df_images.loc[df_images.id == img_i['id'], 'entity_id'] = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_images.to_csv('./df_images.csv', index = False) #Обновляем \"базу знаний\" про связки с id Wikibase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Заливка деталей\n",
    "df_parts_img = df_parts[df_parts.image_id.isin(df_images[~df_images.entity_id.isnull()].id)] #только тех, для которых мы уже залили картинки\n",
    "for _, part_i in df_parts_img.iterrows():\n",
    "    part_img = part_i['image_id']\n",
    "    img_Q = df_images[df_images.id == part_img].reset_index().at[0, 'entity_id']\n",
    "    \n",
    "    data = [\n",
    "        wbi_core.String(str(part_i['name']), prop_nr=ITEMS_DICT['P']['Part Name']),\n",
    "        wbi_core.String(str(part_i['tag']), prop_nr=ITEMS_DICT['P']['Part Tag']),\n",
    "        wbi_core.String(str(part_i['part_num']), prop_nr=ITEMS_DICT['P']['Part Num']),\n",
    "        wbi_core.ItemID(ITEMS_DICT['I']['Brickit Part'], prop_nr=ITEMS_DICT['P']['instance of']),\n",
    "        wbi_core.ItemID(img_Q, prop_nr=ITEMS_DICT['P']['Part Image'])\n",
    "    ]\n",
    "    item = wbi_core.ItemEngine(new_item=True, data=data,core_props=set())\n",
    "    \n",
    "    # Этот метод в библиотеке из коробки не работает. \n",
    "    item.set_label('part_num_' + str(part_i['part_num']), if_exists='REPLACE')\n",
    "    \n",
    "    r = item.write(login_instance)    \n",
    "    \n",
    "    df_parts.loc[df_parts.part_num == part_i['part_num'], 'entity_id'] = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parts.to_csv('./df_parts.csv', index = False) #Обновляем \"базу знаний\" про связки с id Wikibase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Эвотор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выгрузка схемы базы из Эвотора\n",
    "'''\n",
    "select col.column_id, \n",
    "       col.owner as schema_name,\n",
    "       col.table_name, \n",
    "       col.column_name, \n",
    "       col.data_type, \n",
    "       col.data_length, \n",
    "       col.data_precision, \n",
    "       col.data_scale, \n",
    "       col.nullable\n",
    "from sys.all_tab_columns col\n",
    "inner join sys.all_tables t on col.owner = t.owner \n",
    "                              and col.table_name = t.table_name\n",
    "-- excluding some Oracle maintained schemas\n",
    "where col.owner not in ('ANONYMOUS','CTXSYS','DBSNMP','EXFSYS', 'LBACSYS', \n",
    "   'MDSYS', 'MGMT_VIEW','OLAPSYS','OWBSYS','ORDPLUGINS', 'ORDSYS','OUTLN', \n",
    "   'SI_INFORMTN_SCHEMA','SYS','SYSMAN','SYSTEM','TSMSYS','WK_TEST','WKSYS', \n",
    "   'WKPROXY','WMSYS','XDB','APEX_040000', 'APEX_PUBLIC_USER','DIP', \n",
    "   'FLOWS_30000','FLOWS_FILES','MDDATA', 'ORACLE_OCM', 'XS$NULL',\n",
    "   'SPATIAL_CSW_ADMIN_USR', 'SPATIAL_WFS_ADMIN_USR', 'PUBLIC')  \n",
    "order by col.owner, col.table_name, col.column_id;\n",
    "'''\n",
    "\n",
    "df_e = pd.read_csv('./evotor_schemas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Возьмём самые ходовые схемы для тестов\n",
    "schema_list = [\n",
    "    'AIRFLOW', \n",
    "    'BIGDATA_LOADER', \n",
    "    'EVOTOR_ANALYTICS', \n",
    "    'EVOTOR_BIGDATA', \n",
    "    'EVOTOR_MARKET_REPL',\n",
    "    'EVOTOR_REPORTS',\n",
    "    'EVOTOR_CRM'\n",
    "]\n",
    "df_e = df_e[df_e.SCHEMA_NAME.isin(schema_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Какие properties будут нужны \n",
    "prop_list = ['Field', 'Description', 'Schema','Table','located in','Data Type','Data Length']\n",
    "prop_df = get_items_by_label(prop_list, item_type = 'P')\n",
    "prop_df = {i['label']: i['item'] for _, i in prop_df.iterrows()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание схем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_database = get_items_by_label(['dwh'], item_type = 'Q').at[0, 'item']\n",
    "for schema in schema_list:\n",
    "    data = [\n",
    "        wbi_core.ItemID(Q_database, prop_nr=prop_df['located in'])\n",
    "    ]\n",
    "    item = wbi_core.ItemEngine(new_item=True, data=data,core_props=set())\n",
    "\n",
    "    item.set_label(schema, if_exists='REPLACE')\n",
    "\n",
    "    r = item.write(login_instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание таблиц"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for schema in tqdm(schema_list):\n",
    "    print(schema)\n",
    "    Q_schema = get_items_by_label([schema], item_type = 'Q').at[0, 'item'] # ID объекта DWH\n",
    "    df_schema = df_e[df_e.SCHEMA_NAME == schema]\n",
    "    \n",
    "    # Таблицы\n",
    "    for table in tqdm(df_schema.TABLE_NAME.unique()):\n",
    "        if '#' in table:\n",
    "            continue\n",
    "        \n",
    "        df_table = df_schema[df_schema.TABLE_NAME == table]\n",
    "        \n",
    "        fields = []\n",
    "        # Квалифаеры\n",
    "        for _, field in df_table.iterrows(): \n",
    "            qualifiers = [\n",
    "                wbi_core.String(field['DATA_TYPE'], prop_nr=prop_df['Data Type'], is_qualifier = True),\n",
    "                wbi_core.String(str(field['DATA_LENGTH']), prop_nr=prop_df['Data Length'], is_qualifier = True),\n",
    "            ]\n",
    "            # Поля\n",
    "            fields.append(wbi_core.String(field['COLUMN_NAME'], prop_nr=prop_df['Field'], qualifiers=qualifiers))\n",
    "                \n",
    "        data = [wbi_core.ItemID(Q_schema, prop_nr=prop_df['located in'])]\n",
    "        data.extend(fields)\n",
    "        \n",
    "        item = wbi_core.ItemEngine(new_item=True, data=data,core_props=set())\n",
    "\n",
    "        item.set_label(schema + '.' + table, if_exists='REPLACE')\n",
    "\n",
    "        r = item.write(login_instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Перечислить таблицы в схемах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for schema in schema_list:\n",
    "    print(schema)\n",
    "    Q_schema = get_items_by_label([schema], item_type = 'Q').at[0, 'item'] # ID объекта DWH\n",
    "\n",
    "    df_schema = df_e[(df_e.SCHEMA_NAME == schema) & (~df_e.TABLE_NAME.str.contains('#'))]\n",
    "    df_schema['lables'] = df_schema.SCHEMA_NAME + '.' + df_schema.TABLE_NAME\n",
    "    \n",
    "    lables_list = list(set(df_schema.lables))\n",
    "    \n",
    "    batch = 25\n",
    "    Q_tables = []\n",
    "    for i in tqdm(range(ceil(len(lables_list) / batch)), desc = 'batches'):\n",
    "        lables_list_i = lables_list[batch*i : batch*(i+1)]\n",
    "        Q_tables_i = get_items_by_label(lables_list_i, item_type = 'Q').item.to_list()\n",
    "        Q_tables.extend(Q_tables_i)\n",
    "        \n",
    "    data = [wbi_core.ItemID(Q_i, prop_nr=prop_df['Table']) for Q_i in Q_tables]\n",
    "\n",
    "    item = wbi_core.ItemEngine(new_item=False, item_id = Q_schema, data=data,core_props=set())\n",
    "\n",
    "    item.write(login_instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Прочие знания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API поиска\n",
    "wbi_core.ItemEngine.get_search_results('part_num_10793') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Дескрипшн\n",
    "set_description(self, description, lang=None, if_exists='REPLACE'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обновление существующих айтемов\n",
    "data = [\n",
    "    wbi_core.ItemID(img_Q, prop_nr = ITEMS_DICT['P']['Part Image'])\n",
    "]\n",
    "item = wbi_core.ItemEngine(new_item=False, item_id = 'Q1234', data=data,core_props=set())\n",
    "r = item.write(login_instance)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
