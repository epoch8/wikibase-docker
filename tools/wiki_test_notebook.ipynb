{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, MetaData, Table, Column, Integer, String, DateTime, Float, select, Date, JSON\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from math import ceil\n",
    "from tqdm import tqdm\n",
    "from pandas.util.testing import assert_frame_equal\n",
    "\n",
    "from wikibaseintegrator import wbi_core, wbi_login, wbi_login\n",
    "from wikibaseintegrator.wbi_config import config as wbi_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "BRICKIT_BD_LOGIN = 'postgres'\n",
    "BRICKIT_BD_PASSWORD = 'pass'\n",
    "BRICKIT_BD_HOST = 'host'\n",
    "WIKIBASE_HOST = '84.201.142.182'\n",
    "\n",
    "WIKIBASE_LOGIN = 'WikibaseAdmin'\n",
    "WIKIBASE_PASSWORD = 'WikibaseDockerAdminPass'\n",
    "\n",
    "connection_string = f'postgresql://{BRICKIT_BD_LOGIN}:{BRICKIT_BD_PASSWORD}@{BRICKIT_BD_HOST}:5432/holybricks'\n",
    "engine_pg = create_engine(connection_string)\n",
    "\n",
    "wbi_config['MEDIAWIKI_API_URL'] = f'http://{WIKIBASE_HOST}:8181/api.php'\n",
    "wbi_config['SPARQL_ENDPOINT_URL'] = f'http://{WIKIBASE_HOST}:8989/bigdata/sparql'\n",
    "wbi_config['WIKIBASE_URL'] = 'http://wikibase.svc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Легаси, уже умеем нормально\n",
    "ITEMS_DICT = {\n",
    "    'I': {\n",
    "        'Brickit Company': 'Q1',\n",
    "        'Brickit Image': 'Q2',\n",
    "        'Brickit Part': 'Q3'\n",
    "\n",
    "    },\n",
    "    'P': {\n",
    "        'instance of': 'P1',\n",
    "        'Image URL': 'P2',\n",
    "        'Image ID': 'P3',\n",
    "        'Part Name': 'P4',\n",
    "        'Part Tag': 'P5',\n",
    "        'Part Image': 'P6',\n",
    "        'Part Num': 'P7',\n",
    "        'Part Child': 'P8'\n",
    "    }    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Забрать какие-то данные из Brickit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_images = pd.read_sql(f\"\"\"\n",
    "SELECT id, public_url\n",
    "FROM staging.manual_images\n",
    "WHERE initial_entity_type = 'part'\n",
    "    \"\"\", con = engine_pg)\n",
    "\n",
    "\n",
    "df_parts = pd.read_sql(f\"\"\"\n",
    "SELECT part_num, \"name\", tag, part_cat_id, child_part_nums, image_id\n",
    "FROM staging.synthetic_parts\n",
    "    \"\"\", con = engine_pg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Залить сущности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Костыль для связки наша сущность - ID в Wikibase/\n",
    "# Предполагаем, что это можно взять при помощи SPARQL\n",
    "# А пока что по результатам циклов ниже в эти датафреймы дописывается ID Wikibase и сохраняются в csv\n",
    "# df_images = pd.read_csv('./df_images.csv')\n",
    "# df_parts = pd.read_csv('./df_parts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "login_instance = wbi_login.Login(user=WIKIBASE_LOGIN, pwd=WIKIBASE_PASSWORD)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузить 100 изображений из всех\n",
    "for _, img_i in df_images[:100].iterrows():\n",
    "    data = [\n",
    "        wbi_core.Url(str(img_i['public_url']), prop_nr=ITEMS_DICT['P']['Image URL']),\n",
    "        wbi_core.String(str(img_i['id']), prop_nr=ITEMS_DICT['P']['Image ID']),\n",
    "        wbi_core.ItemID(ITEMS_DICT['I']['Brickit Image'], prop_nr=ITEMS_DICT['P']['instance of'])\n",
    "    ]\n",
    "    item = wbi_core.ItemEngine(new_item=True, data=data,core_props=set())\n",
    "    \n",
    "    # Этот метод в библиотеке из коробки не работает. \n",
    "    # Надо либо закомментить в библиотеке в wbi_core.ItemEngine.set_label() условие после \"Skip set_label if the item already have one and if_exists is at 'KEEP'\"\n",
    "    # Либо просто не проставлять лейблы\n",
    "    item.set_label('img_' + str(img_i['id']), if_exists='REPLACE')\n",
    "    \n",
    "    r = item.write(login_instance)    \n",
    "    \n",
    "    df_images.loc[df_images.id == img_i['id'], 'entity_id'] = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_images.to_csv('./df_images.csv', index = False) #Обновляем \"базу знаний\" про связки с id Wikibase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Заливка деталей\n",
    "df_parts_img = df_parts[df_parts.image_id.isin(df_images[~df_images.entity_id.isnull()].id)] #только тех, для которых мы уже залили картинки\n",
    "for _, part_i in df_parts_img.iterrows():\n",
    "    part_img = part_i['image_id']\n",
    "    img_Q = df_images[df_images.id == part_img].reset_index().at[0, 'entity_id']\n",
    "    \n",
    "    data = [\n",
    "        wbi_core.String(str(part_i['name']), prop_nr=ITEMS_DICT['P']['Part Name']),\n",
    "        wbi_core.String(str(part_i['tag']), prop_nr=ITEMS_DICT['P']['Part Tag']),\n",
    "        wbi_core.String(str(part_i['part_num']), prop_nr=ITEMS_DICT['P']['Part Num']),\n",
    "        wbi_core.ItemID(ITEMS_DICT['I']['Brickit Part'], prop_nr=ITEMS_DICT['P']['instance of']),\n",
    "        wbi_core.ItemID(img_Q, prop_nr=ITEMS_DICT['P']['Part Image'])\n",
    "    ]\n",
    "    item = wbi_core.ItemEngine(new_item=True, data=data,core_props=set())\n",
    "    \n",
    "    # Этот метод в библиотеке из коробки не работает. \n",
    "    item.set_label('part_num_' + str(part_i['part_num']), if_exists='REPLACE')\n",
    "    \n",
    "    r = item.write(login_instance)    \n",
    "    \n",
    "    df_parts.loc[df_parts.part_num == part_i['part_num'], 'entity_id'] = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parts.to_csv('./df_parts.csv', index = False) #Обновляем \"базу знаний\" про связки с id Wikibase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Эвотор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выгрузка схемы базы из Эвотора\n",
    "'''\n",
    "select col.column_id, \n",
    "       col.owner as schema_name,\n",
    "       col.table_name, \n",
    "       col.column_name, \n",
    "       col.data_type, \n",
    "       col.data_length, \n",
    "       col.data_precision, \n",
    "       col.data_scale, \n",
    "       col.nullable\n",
    "from sys.all_tab_columns col\n",
    "inner join sys.all_tables t on col.owner = t.owner \n",
    "                              and col.table_name = t.table_name\n",
    "-- excluding some Oracle maintained schemas\n",
    "where col.owner not in ('ANONYMOUS','CTXSYS','DBSNMP','EXFSYS', 'LBACSYS', \n",
    "   'MDSYS', 'MGMT_VIEW','OLAPSYS','OWBSYS','ORDPLUGINS', 'ORDSYS','OUTLN', \n",
    "   'SI_INFORMTN_SCHEMA','SYS','SYSMAN','SYSTEM','TSMSYS','WK_TEST','WKSYS', \n",
    "   'WKPROXY','WMSYS','XDB','APEX_040000', 'APEX_PUBLIC_USER','DIP', \n",
    "   'FLOWS_30000','FLOWS_FILES','MDDATA', 'ORACLE_OCM', 'XS$NULL',\n",
    "   'SPATIAL_CSW_ADMIN_USR', 'SPATIAL_WFS_ADMIN_USR', 'PUBLIC')  \n",
    "order by col.owner, col.table_name, col.column_id;\n",
    "'''\n",
    "\n",
    "df_e = pd.read_csv('./evotor_schemas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Возьмём самые ходовые схемы для тестов\n",
    "schema_list = [\n",
    "    'AIRFLOW', \n",
    "    'BIGDATA_LOADER', \n",
    "    'EVOTOR_ANALYTICS', \n",
    "    'EVOTOR_BIGDATA', \n",
    "    'EVOTOR_MARKET_REPL',\n",
    "    'EVOTOR_REPORTS',\n",
    "    'EVOTOR_CRM'\n",
    "]\n",
    "df_e = df_e[df_e.SCHEMA_NAME.isin(schema_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Какие properties будут нужны \n",
    "prop_list = ['Field', 'Description', 'Schema','Table','located in','Data Type','Data Length']\n",
    "prop_df = get_items_by_label(prop_list, item_type = 'P')\n",
    "prop_df = {i['label']: i['item'] for _, i in prop_df.iterrows()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание схем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_database = get_items_by_label(['dwh'], item_type = 'Q').at[0, 'item']\n",
    "for schema in schema_list:\n",
    "    data = [\n",
    "        wbi_core.ItemID(Q_database, prop_nr=prop_df['located in'])\n",
    "    ]\n",
    "    item = wbi_core.ItemEngine(new_item=True, data=data,core_props=set())\n",
    "\n",
    "    item.set_label(schema, if_exists='REPLACE')\n",
    "\n",
    "    r = item.write(login_instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание таблиц"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for schema in tqdm(schema_list):\n",
    "    print(schema)\n",
    "    Q_schema = get_items_by_label([schema], item_type = 'Q').at[0, 'item'] # ID объекта DWH\n",
    "    df_schema = df_e[df_e.SCHEMA_NAME == schema]\n",
    "    \n",
    "    # Таблицы\n",
    "    for table in tqdm(df_schema.TABLE_NAME.unique()):\n",
    "        if '#' in table:\n",
    "            continue\n",
    "        \n",
    "        df_table = df_schema[df_schema.TABLE_NAME == table]\n",
    "        \n",
    "        fields = []\n",
    "        # Квалифаеры\n",
    "        for _, field in df_table.iterrows(): \n",
    "            qualifiers = [\n",
    "                wbi_core.String(field['DATA_TYPE'], prop_nr=prop_df['Data Type'], is_qualifier = True),\n",
    "                wbi_core.String(str(field['DATA_LENGTH']), prop_nr=prop_df['Data Length'], is_qualifier = True),\n",
    "            ]\n",
    "            # Поля\n",
    "            fields.append(wbi_core.String(field['COLUMN_NAME'], prop_nr=prop_df['Field'], qualifiers=qualifiers))\n",
    "                \n",
    "        data = [wbi_core.ItemID(Q_schema, prop_nr=prop_df['located in'])]\n",
    "        data.extend(fields)\n",
    "        \n",
    "        item = wbi_core.ItemEngine(new_item=True, data=data,core_props=set())\n",
    "\n",
    "        item.set_label(schema + '.' + table, if_exists='REPLACE')\n",
    "\n",
    "        r = item.write(login_instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Перечислить таблицы в схемах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for schema in schema_list:\n",
    "    print(schema)\n",
    "    Q_schema = get_items_by_label([schema], item_type = 'Q').at[0, 'item'] # ID объекта DWH\n",
    "\n",
    "    df_schema = df_e[(df_e.SCHEMA_NAME == schema) & (~df_e.TABLE_NAME.str.contains('#'))]\n",
    "    df_schema['lables'] = df_schema.SCHEMA_NAME + '.' + df_schema.TABLE_NAME\n",
    "    \n",
    "    lables_list = list(set(df_schema.lables))\n",
    "    \n",
    "    batch = 25\n",
    "    Q_tables = []\n",
    "    for i in tqdm(range(ceil(len(lables_list) / batch)), desc = 'batches'):\n",
    "        lables_list_i = lables_list[batch*i : batch*(i+1)]\n",
    "        Q_tables_i = get_items_by_label(lables_list_i, item_type = 'Q').item.to_list()\n",
    "        Q_tables.extend(Q_tables_i)\n",
    "        \n",
    "    data = [wbi_core.ItemID(Q_i, prop_nr=prop_df['Table']) for Q_i in Q_tables]\n",
    "\n",
    "    item = wbi_core.ItemEngine(new_item=False, item_id = Q_schema, data=data,core_props=set())\n",
    "\n",
    "    item.write(login_instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Классы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_items_by_label(label_list:list, item_type:str, is_unique:bool = True, is_notnull:bool = True):\n",
    "    '''\n",
    "    По переданному списку лейблов находит entity_id в базе Wikibase. \n",
    "    \n",
    "    label_list: список искомых лейблов\n",
    "    item_type: тип искомого объекта. Если не указано, то любой объект. Если указано:\n",
    "        \"P\" - Property\n",
    "        \"Q\" - Item\n",
    "    is_unique: если True, то вернёт ошибку, если найдено больше одного значения\n",
    "    is_notnull: если True, то вернёт ошибку, если не найдено ни одного значения\n",
    "    '''\n",
    "    \n",
    "    query = \"\"\"\n",
    "        SELECT DISTINCT ?item ?itemLabel\n",
    "        WHERE {{\n",
    "          ?item rdfs:label ?itemLabel. \n",
    "\n",
    "          VALUES ?itemLabel {{ {label_filter} }}\n",
    "        }}\"\"\".format(label_filter = ' '.join([f'\\\"{i}\\\"@en' for i in label_list]))\n",
    "    \n",
    "    result = wbi_core.ItemEngine.execute_sparql_query(query)\n",
    "    result_list = [[i['itemLabel']['value'], i['item']['value'].replace('http://wikibase.svc/entity/', '')] \n",
    "                   for i in result['results']['bindings']]\n",
    "    \n",
    "    df = pd.DataFrame(result_list, columns = ['label', 'item'])\n",
    "        \n",
    "    if item_type in ('P', 'Q'):\n",
    "        df = df[df.item.str.contains(item_type)] \n",
    "\n",
    "    df_check = df.groupby('label').count()\n",
    "    if is_unique and df_check.item.max() > 1:\n",
    "        r = df[df.label.isin(df_check[df_check.item > 1].index.to_list())].sort_values(by = 'label')\n",
    "        logging.info(f\"entity_id определён неоднозначно: \\n{r}\")\n",
    "        return None\n",
    "    elif is_notnull and len(set(label_list) - set(df.label)) > 0:\n",
    "        r = set(label_list) - set(df.label)\n",
    "        logging.info(f\"entity_id не найден: \\n{r}!\")\n",
    "        return None\n",
    "    else:\n",
    "        return df\n",
    "    \n",
    "    \n",
    "def get_wb_parent(Q:str, P:str, login_instance:wbi_login.Login) -> str:\n",
    "    '''\n",
    "    Свойством P какого объекта-родителя является объект Q? Возвращает ошибку, если родителей ноль или несколько.\n",
    "        Q - целевой объект\n",
    "        P - каким параметром он должен быть\n",
    "    '''\n",
    "\n",
    "    query = f'''\n",
    "        SELECT ?entity_id ?entity_name WHERE {{\n",
    "            ?entity_id wdt:{P} wd:{Q} .\n",
    "            ?entity_id rdfs:label ?entity_name .\n",
    "        }}'''\n",
    "    print(query)\n",
    "    result = wbi_core.ItemEngine.execute_sparql_query(query)\n",
    "\n",
    "    result_list = [[i['entity_name']['value'], i['entity_id']['value'].replace('http://wikibase.svc/entity/', '')]\n",
    "                   for i in result['results']['bindings']]\n",
    "\n",
    "    result_df = pd.DataFrame(result_list, columns = ['entity_name', 'entity_id'])\n",
    "\n",
    "    if result_df.shape[0] > 1:\n",
    "        raise Exception(f'Object with entity_id {Q} have several parents: \\n{result_df.entity_id.to_list()}')\n",
    "    elif result_df.shape[0] == 0:\n",
    "        raise Exception(f'Object with entity_id {Q} not finded in !')\n",
    "    else:\n",
    "        return (result_df.at[0, 'entity_name'], result_df.at[0, 'entity_id'])\n",
    "\n",
    "    \n",
    "def get_wb_statement(Q:str, property_dict:dict, login_instance:wbi_login.Login) -> pd.DataFrame:\n",
    "    '''\n",
    "    Для объекта Q для стейтмента P вывести все его значения с квалифаерами\n",
    "        Q - для какого объекта ищем\n",
    "        P - какой стейтмент (например, P11 - Field)\n",
    "        property_dict - словарь вида:\n",
    "            {\n",
    "                statement: 'P111'\n",
    "                core_qualifiers: {\n",
    "                   'any_title': 'P123'\n",
    "                },\n",
    "                custom_qualifiers: {\n",
    "                    'any_title': 'P456'\n",
    "                }                \n",
    "            }\n",
    "            , где core_fields - обязательные поля, custom_fields - опциональные, могут быть пустыми        \n",
    "    '''\n",
    "    P = property_dict['statement']\n",
    "\n",
    "    q_column_names = ['?{} '.format(i.replace(' ', '_')) for i in property_dict['core_qualifiers'].keys()]\n",
    "    q_column_names_custom = ['?{} '.format(i.replace(' ', '_')) for i in property_dict['custom_qualifiers'].keys()]\n",
    "    q_column_names.extend(q_column_names_custom)\n",
    "    q_column_names = ' '.join(q_column_names)\n",
    "    \n",
    "    q_where_core_fields = '\\n'.join([\n",
    "        '?statement pq:{} ?{}.'.format(P, title.replace(' ', '_')) \\\n",
    "            for title, P in property_dict['core_qualifiers'].items()\n",
    "    ])\n",
    "    \n",
    "    q_where_custom_fields = '\\n'.join([\n",
    "        'OPTIONAL {{ ?statement pq:{} ?{}. }}'.format(P, title.replace(' ', '_')) \\\n",
    "            for title, P in property_dict['custom_qualifiers'].items()\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    query = f'''\n",
    "        SELECT ?STATEMENT ?STATEMENT_LABEL {q_column_names}\n",
    "        WHERE\n",
    "        {{\n",
    "             wd:{Q} p:{P} ?statement.\n",
    "             ?statement ps:{P} ?STATEMENT.\n",
    "\n",
    "             {q_where_core_fields}\n",
    "             \n",
    "             OPTIONAL {{ ?STATEMENT rdfs:label ?STATEMENT_LABEL }}\n",
    "\n",
    "             {q_where_custom_fields}                 \n",
    "        }}        \n",
    "    '''\n",
    "\n",
    "    result = wbi_core.ItemEngine.execute_sparql_query(query)\n",
    "\n",
    "    wb_fields_df = []\n",
    "    for bind in result['results']['bindings']:\n",
    "        wb_fields_df.append({k: v['value'] for k, v in bind.items()})\n",
    "    wb_fields_df = pd.DataFrame(wb_fields_df)        \n",
    "\n",
    "    wb_fields_df['STATEMENT'] = wb_fields_df['STATEMENT'].str.replace('http://wikibase.svc/entity/', '')\n",
    "    # Тут хитрость. API SPARQL не вернёт колонку STATEMENT, если ни для одного значения не будет label\n",
    "    # А это тот случай, когда STATEMENT - не айтемы\n",
    "    if 'STATEMENT_LABEL' in wb_fields_df.columns: \n",
    "        wb_fields_df.rename(columns = {\n",
    "            'STATEMENT': 'ITEM_ID',\n",
    "            'STATEMENT_LABEL': 'STATEMENT'\n",
    "        }, inplace = True)\n",
    "        \n",
    "    return wb_fields_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input = pd.read_csv('./evotor_schemas.csv')\n",
    "\n",
    "login_instance = wbi_login.Login(user=WIKIBASE_LOGIN, pwd=WIKIBASE_PASSWORD)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOBAL_PROPERTIES = {\n",
    "    i['label']: i['item'] \\\n",
    "        for _, i in get_items_by_label(['located_in'], item_type = 'P').iterrows()\n",
    "}\n",
    "P_TABLE = get_items_by_label(['TABLE'], item_type = 'P').at[0, 'item']\n",
    "P_SCHEMA = get_items_by_label(['SCHEMA'], item_type = 'P').at[0, 'item']\n",
    "P_DATABASE =  get_items_by_label(['DATABASE'], item_type = 'P').at[0, 'item']\n",
    "P_COLUMN =  get_items_by_label(['COLUMN'], item_type = 'P').at[0, 'item']\n",
    "\n",
    "\n",
    "\n",
    "PROPERTY_DICT = {\n",
    "    'COMPANY': {\n",
    "        'repeated_statement': {   \n",
    "            'label': 'DATABASE',   \n",
    "            'statement': P_DATABASE,     \n",
    "            'core_qualifiers': {},\n",
    "            'custom_qualifiers': {\n",
    "                i['label']: i['item'] \\\n",
    "                    for _, i in get_items_by_label(['DESCRIPTION'], item_type = 'P').iterrows()\n",
    "            }        \n",
    "        },\n",
    "        'global': GLOBAL_PROPERTIES\n",
    "    },\n",
    "    'DATABASE': {\n",
    "        'in_property': P_DATABASE,\n",
    "        'repeated_statement': {     \n",
    "            'label': 'SCHEMA',    \n",
    "            'statement': P_SCHEMA,        \n",
    "            'core_qualifiers': {},\n",
    "            'custom_qualifiers': {\n",
    "                i['label']: i['item'] \\\n",
    "                    for _, i in get_items_by_label(['DESCRIPTION'], item_type = 'P').iterrows()\n",
    "            }        \n",
    "        },\n",
    "        'global': GLOBAL_PROPERTIES       \n",
    "    },\n",
    "    'SCHEMA': {\n",
    "        'in_property': P_SCHEMA,\n",
    "        'repeated_statement': {   \n",
    "            'label': 'TABLE',     \n",
    "            'statement': P_TABLE,        \n",
    "            'core_qualifiers': {},\n",
    "            'custom_qualifiers': {\n",
    "                i['label']: i['item'] \\\n",
    "                    for _, i in get_items_by_label(['DESCRIPTION'], item_type = 'P').iterrows()\n",
    "            }        \n",
    "        },\n",
    "        'global': GLOBAL_PROPERTIES   \n",
    "    },\n",
    "    'TABLE': {\n",
    "        'in_property': P_TABLE,\n",
    "        'repeated_statement': {\n",
    "            'label': 'COLUMN',\n",
    "            'statement': P_COLUMN,        \n",
    "            'core_qualifiers': {\n",
    "                i['label']: i['item'] \\\n",
    "                    for _, i in get_items_by_label(['DATA_TYPE','DATA_LENGTH'], item_type = 'P').iterrows()\n",
    "            },\n",
    "            'custom_qualifiers': {\n",
    "                i['label']: i['item'] \\\n",
    "                    for _, i in get_items_by_label(['DESCRIPTION'], item_type = 'P').iterrows()\n",
    "            }        \n",
    "        },\n",
    "        'global': GLOBAL_PROPERTIES\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WikiObject():\n",
    "    def _fetch_qualifiers(self):\n",
    "        if self.new_item:\n",
    "            self.resolved_fields = df_input.copy()\n",
    "        elif self.df_input.shape[0] == 0:\n",
    "            logging.info('No input dataframe, can`t fetch!')\n",
    "        else:\n",
    "            merge_column = self.properties_dict['repeated_statement']['label']\n",
    "            \n",
    "            logging.info(\"\"\"\n",
    "                {columns} statements in new table\n",
    "                {added} statements are added\n",
    "                {deleted} statements are deleted              \n",
    "            \"\"\".format(\n",
    "                columns = self.df_input.shape[0],\n",
    "                added = self.df_input[~self.df_input[merge_column].isin(self.wb_fields.STATEMENT)].shape[0],\n",
    "                deleted = self.wb_fields[~self.wb_fields.STATEMENT.isin(self.df_input[merge_column])].shape[0]                    \n",
    "            ))\n",
    "\n",
    "            fetched_column = [merge_column]\n",
    "            fetched_column.extend(self.properties_dict['repeated_statement']['custom_qualifiers'].keys())\n",
    "            \n",
    "            \n",
    "            self.resolved_fields = self.df_input.merge(self.wb_fields.STATEMENT,\n",
    "                                                 how = 'outer', left_on = merge_column, right_on = 'STATEMENT')\n",
    "            \n",
    "            self.resolved_fields['is_deleted'] = self.resolved_fields\\\n",
    "                .apply(lambda row: 1 if pd.isnull(row[merge_column]) else 0, axis = 1)\n",
    "            \n",
    "            return self.resolved_fields\n",
    "    \n",
    "    \n",
    "    def _set_vars(self):\n",
    "        Q_df = get_items_by_label([self.name], item_type = 'Q')\n",
    "        if Q_df is None:  \n",
    "            # Новый объект\n",
    "            logging.info(f'No such object: {name}! New one will be created.')\n",
    "            assert self.df_input.shape[0] > 1 , 'Cannot create new item from empty input DataFrame!'\n",
    "            \n",
    "            parent_label = df_input[self.in_property_label].unique()\n",
    "            assert parent_label.shape[0] == 1 , f'Ambiguous parent_label: {parent_label} '\n",
    "            \n",
    "            self.parent_label = parent_label[0]\n",
    "            self.Q_parent = get_items_by_label([self.parent_label], item_type = 'Q').at[0, 'item']            \n",
    "            self.Q = None\n",
    "            self.new_item = True            \n",
    "        else:\n",
    "            # Существующий объект\n",
    "            self.Q = Q_df.at[0, 'item']\n",
    "            self.parent_label, self.Q_parent = get_wb_parent(self.Q, self.properties_dict['in_property'], self.login_instance)\n",
    "            self.wb_fields = get_wb_statement(self.Q, self.properties_dict['repeated_statement'], self.login_instance)\n",
    "            self.new_item = False\n",
    "        \n",
    "        self._fetch_qualifiers()\n",
    "        logging.info(\"\"\"\n",
    "            Object {name} (entity_id: {Q}), parent {parent_label} (entity_id: {Qp})\n",
    "        \"\"\".format(\n",
    "            name = self.name,\n",
    "            Q = self.Q,\n",
    "            parent_label = self.parent_label,\n",
    "            Qp = self.Q_parent\n",
    "        ))\n",
    "        \n",
    "        \n",
    "    def delete_item(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WikiTable(WikiObject): \n",
    "    def __init__(\n",
    "        self, \n",
    "        name:str, \n",
    "        properties_dict:dict, \n",
    "        login_instance:wbi_login.Login, \n",
    "        df_input = pd.DataFrame()\n",
    "    ):        \n",
    "        self.name = name\n",
    "        self.login_instance = login_instance\n",
    "        self.properties_dict = properties_dict['TABLE']\n",
    "        self.df_input = df_input\n",
    "        self.in_property_label = 'SCHEMA'\n",
    "        self._set_vars()\n",
    "        self.df_input = df_input\n",
    "    \n",
    "    \n",
    "    def push_to_wiki(self):\n",
    "        # TO DO: проверка на дубликаты полей\n",
    "        # А это можно на SPARQL сделать? Хотя зачем. \n",
    "        self.resolved_fields\n",
    "\n",
    "        fields = []\n",
    "        # Квалифаеры\n",
    "        for _, field in self.resolved_fields.iterrows(): \n",
    "            qualifiers = [\n",
    "                wbi_core.String(field['DATA_TYPE'], prop_nr=prop_df['Data Type'], is_qualifier = True),\n",
    "                wbi_core.String(str(field['DATA_LENGTH']), prop_nr=prop_df['Data Length'], is_qualifier = True),\n",
    "            ]\n",
    "            description_i =  field['DESCRIPTION']\n",
    "            if description_i:\n",
    "                qualifiers.append(\n",
    "                    wbi_core.String(str(description_i), prop_nr=prop_df['Description'], is_qualifier = True),\n",
    "                )\n",
    "            \n",
    "            # Поля\n",
    "            fields.append(wbi_core.String(field['COLUMN_NAME'], prop_nr=prop_df['Field'], qualifiers=qualifiers))\n",
    "\n",
    "        data = [wbi_core.ItemID(self.Q_schema, prop_nr=prop_df['located in'])]\n",
    "        data.extend(fields)\n",
    "\n",
    "        item = wbi_core.ItemEngine(new_item=self.new_item, data=data,core_props=set())\n",
    "\n",
    "        if self.new_item:\n",
    "            item.set_label(schema + '.' + table, if_exists='REPLACE')\n",
    "\n",
    "        r = item.write(login_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WikiSchema(WikiObject): \n",
    "    def __init__(\n",
    "        self, \n",
    "        name:str, \n",
    "        properties_dict:dict, \n",
    "        login_instance:wbi_login.Login, \n",
    "        df_input = pd.DataFrame()\n",
    "    ):        \n",
    "        self.name = name\n",
    "        self.login_instance = login_instance\n",
    "        self.properties_dict = properties_dict['SCHEMA']\n",
    "        self.df_input = df_input\n",
    "        self.in_property_label = 'DATABASE'\n",
    "        self._set_vars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WikiDatabase(WikiObject): \n",
    "    def __init__(\n",
    "        self, \n",
    "        name:str, \n",
    "        properties_dict:dict, \n",
    "        login_instance:wbi_login.Login, \n",
    "        df_input = pd.DataFrame()\n",
    "    ):        \n",
    "        self.name = name\n",
    "        self.login_instance = login_instance\n",
    "        self.properties_dict = properties_dict['DATABASE']\n",
    "        self.df_input = df_input\n",
    "        self.in_property_label = 'COMPANY'\n",
    "        self._set_vars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\n",
      "                67 statements in new table\n",
      "                0 statements are added\n",
      "                2 statements are deleted              \n",
      "            \n",
      "INFO:root:\n",
      "            Object AIRFLOW.TMP_MP_REVENUE (entity_id: Q270), parent AIRFLOW (entity_id: Q203)\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COLUMN_ID</th>\n",
       "      <th>SCHEMA</th>\n",
       "      <th>TABLE</th>\n",
       "      <th>COLUMN</th>\n",
       "      <th>DATA_TYPE</th>\n",
       "      <th>DATA_LENGTH</th>\n",
       "      <th>DATA_PRECISION</th>\n",
       "      <th>DATA_SCALE</th>\n",
       "      <th>NULLABLE</th>\n",
       "      <th>STATEMENT</th>\n",
       "      <th>is_deleted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>66.0</td>\n",
       "      <td>AIRFLOW</td>\n",
       "      <td>TMP_MP_REVENUE</td>\n",
       "      <td>FL_SAAS</td>\n",
       "      <td>NUMBER</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>FL_SAAS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>68.0</td>\n",
       "      <td>AIRFLOW</td>\n",
       "      <td>TMP_MP_REVENUE</td>\n",
       "      <td>QUANTITY</td>\n",
       "      <td>NUMBER</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>QUANTITY</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>69.0</td>\n",
       "      <td>AIRFLOW</td>\n",
       "      <td>TMP_MP_REVENUE</td>\n",
       "      <td>VAT_SUM</td>\n",
       "      <td>NUMBER</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>VAT_SUM</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NAME</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHANNEL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    COLUMN_ID   SCHEMA           TABLE    COLUMN DATA_TYPE  DATA_LENGTH  \\\n",
       "64       66.0  AIRFLOW  TMP_MP_REVENUE   FL_SAAS    NUMBER         22.0   \n",
       "65       68.0  AIRFLOW  TMP_MP_REVENUE  QUANTITY    NUMBER         22.0   \n",
       "66       69.0  AIRFLOW  TMP_MP_REVENUE   VAT_SUM    NUMBER         22.0   \n",
       "67        NaN      NaN             NaN       NaN       NaN          NaN   \n",
       "68        NaN      NaN             NaN       NaN       NaN          NaN   \n",
       "\n",
       "    DATA_PRECISION  DATA_SCALE NULLABLE STATEMENT  is_deleted  \n",
       "64             NaN         NaN        Y   FL_SAAS           0  \n",
       "65             NaN         0.0        Y  QUANTITY           0  \n",
       "66             NaN         NaN        Y   VAT_SUM           0  \n",
       "67             NaN         NaN      NaN      NAME           1  \n",
       "68             NaN         NaN      NaN   CHANNEL           1  "
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_input_t = df_input[df_input.TABLE == 'TMP_MP_REVENUE']\n",
    "df_input_t = df_input_t.drop([962, 1027])\n",
    "wt = WikiTable('AIRFLOW.TMP_MP_REVENUE', PROPERTY_DICT, login_instance, df_input_t)\n",
    "wt.resolved_fields.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\n",
      "                63 statements in new table\n",
      "                0 statements are added\n",
      "                3 statements are deleted              \n",
      "            \n",
      "INFO:root:\n",
      "            Object AIRFLOW (entity_id: Q203), parent dwh (entity_id: Q196)\n",
      "        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        SELECT ?entity_id ?entity_name WHERE {\n",
      "            ?entity_id wdt:P15 wd:Q203 .\n",
      "            ?entity_id rdfs:label ?entity_name .\n",
      "        }\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCHEMA</th>\n",
       "      <th>TABLE</th>\n",
       "      <th>STATEMENT</th>\n",
       "      <th>is_deleted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>AIRFLOW</td>\n",
       "      <td>AIRFLOW.TMP_SECURITY_USER_GROUP</td>\n",
       "      <td>AIRFLOW.TMP_SECURITY_USER_GROUP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>AIRFLOW</td>\n",
       "      <td>AIRFLOW.T_NAME_STEP_2</td>\n",
       "      <td>AIRFLOW.T_NAME_STEP_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AIRFLOW.TMP_BPLK_1_RUS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AIRFLOW.AF_SALES_REPORT_CORE_PARTNER_1C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AIRFLOW.TMP_SECURITY_USER_PROFILE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     SCHEMA                            TABLE  \\\n",
       "61  AIRFLOW  AIRFLOW.TMP_SECURITY_USER_GROUP   \n",
       "62  AIRFLOW            AIRFLOW.T_NAME_STEP_2   \n",
       "63      NaN                              NaN   \n",
       "64      NaN                              NaN   \n",
       "65      NaN                              NaN   \n",
       "\n",
       "                                  STATEMENT  is_deleted  \n",
       "61          AIRFLOW.TMP_SECURITY_USER_GROUP           0  \n",
       "62                    AIRFLOW.T_NAME_STEP_2           0  \n",
       "63                   AIRFLOW.TMP_BPLK_1_RUS           1  \n",
       "64  AIRFLOW.AF_SALES_REPORT_CORE_PARTNER_1C           1  \n",
       "65        AIRFLOW.TMP_SECURITY_USER_PROFILE           1  "
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_input_s = df_input[df_input.SCHEMA == 'AIRFLOW'][['SCHEMA', 'TABLE']].drop_duplicates()\n",
    "df_input_s['TABLE'] = df_input_s['SCHEMA'] + '.' + df_input_s['TABLE']\n",
    "df_input_s = df_input_s.drop([0, 1124])\n",
    "ws = WikiDatabase('AIRFLOW', PROPERTY_DICT, login_instance, df_input_s)\n",
    "ws.resolved_fields.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input_s = df_input[df_input.SCHEMA == 'AIRFLOW'][['SCHEMA', 'TABLE']].drop_duplicates()\n",
    "df_input_s['TABLE'] = df_input_s['SCHEMA'] + '.' + df_input_s['TABLE']\n",
    "df_input_s = df_input_s.drop([0, 1124])\n",
    "ws = WikiSchema('AIRFLOW', PROPERTY_DICT, login_instance, df_input_s)\n",
    "ws.resolved_fields.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\n",
      "                6 statements in new table\n",
      "                0 statements are added\n",
      "                1 statements are deleted              \n",
      "            \n",
      "INFO:root:\n",
      "            Object dwh (entity_id: Q196), parent Evotor Company (entity_id: Q191)\n",
      "        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        SELECT ?entity_id ?entity_name WHERE {\n",
      "            ?entity_id wdt:P14 wd:Q196 .\n",
      "            ?entity_id rdfs:label ?entity_name .\n",
      "        }\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCHEMA</th>\n",
       "      <th>DATABASE</th>\n",
       "      <th>STATEMENT</th>\n",
       "      <th>is_deleted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EVOTOR_ANALYTICS</td>\n",
       "      <td>dwh</td>\n",
       "      <td>EVOTOR_ANALYTICS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EVOTOR_BIGDATA</td>\n",
       "      <td>dwh</td>\n",
       "      <td>EVOTOR_BIGDATA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EVOTOR_MARKET_REPL</td>\n",
       "      <td>dwh</td>\n",
       "      <td>EVOTOR_MARKET_REPL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EVOTOR_REPORTS</td>\n",
       "      <td>dwh</td>\n",
       "      <td>EVOTOR_REPORTS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EVOTOR_CRM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               SCHEMA DATABASE           STATEMENT  is_deleted\n",
       "2    EVOTOR_ANALYTICS      dwh    EVOTOR_ANALYTICS           0\n",
       "3      EVOTOR_BIGDATA      dwh      EVOTOR_BIGDATA           0\n",
       "4  EVOTOR_MARKET_REPL      dwh  EVOTOR_MARKET_REPL           0\n",
       "5      EVOTOR_REPORTS      dwh      EVOTOR_REPORTS           0\n",
       "6                 NaN      NaN          EVOTOR_CRM           1"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema_list = [\n",
    "    'AIRFLOW', \n",
    "    'BIGDATA_LOADER', \n",
    "    'EVOTOR_ANALYTICS', \n",
    "    'EVOTOR_BIGDATA', \n",
    "    'EVOTOR_MARKET_REPL',\n",
    "    'EVOTOR_REPORTS'\n",
    "#     'EVOTOR_CRM'\n",
    "]\n",
    "\n",
    "df_input_d = df_input[['SCHEMA']].drop_duplicates()\n",
    "df_input_d['DATABASE'] = 'dwh'\n",
    "df_input_d = df_input_d[df_input_d.SCHEMA.isin(schema_list)]\n",
    "wd = WikiDatabase('dwh', PROPERTY_DICT, login_instance, df_input_d)\n",
    "wd.resolved_fields.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Прочие знания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API поиска\n",
    "wbi_core.ItemEngine.get_search_results('part_num_10793') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Дескрипшн\n",
    "set_description(self, description, lang=None, if_exists='REPLACE'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обновление существующих айтемов\n",
    "data = [\n",
    "    wbi_core.ItemID(img_Q, prop_nr = ITEMS_DICT['P']['Part Image'])\n",
    "]\n",
    "item = wbi_core.ItemEngine(new_item=False, item_id = 'Q1234', data=data,core_props=set())\n",
    "r = item.write(login_instance)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
